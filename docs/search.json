[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Methods for Structural Microeconometrics",
    "section": "",
    "text": "Welcome to this course! Find details on the syllabus here, and check out the menu to find other materials.\nHere is a link to the git repo for this course, which by cloning is probably the simplest way for you to get access to the data, code, and assignments. I will continue to add materials throughout the course. You may prefer to selectively download these materials."
  },
  {
    "objectID": "index.html#topics",
    "href": "index.html#topics",
    "title": "Methods for Structural Microeconometrics",
    "section": "Topics",
    "text": "Topics\n\nIdentification, Credible Inference, and Marschak’s Maxim\n2024 is the last year I will make this topic a part of the course.\nWe formally define identification and discuss (via examples) what people really mean when they talk about identification and credible inference. We use the Generalized Roy Model to compare identification via functional form to nonparametric identification.\nWe introduce Marschak’s Maxim as a guide for doing empirical model-based research.\n\nReading\nThe two survey articles by Keane (2010) (link) and Angrist and Pischke (2010) (link) - although aging - provide two important perspectives on the issues of credible inference in economics. Low and Meghir (2017) provide a nice review of the advantages of the structural approach.\nThe original paper by Marschak (1953) may be of interest. Heckman and Vytlacil (2007) provide a nice discussion of Marschak’s Maxim in the context of policy evaluation. They introduce (Heckman and Vytlacil 2005; Carneiro, Heckman, and Vytlacil 2011) the Marginal Treatment Effect as a tool for thinking about quasi-experimental estimators and policy evaluation.\n\n\n\nDynamic Discrete Choice\nWe introduce the dynamic discrete choice model and briefly discuss identification when all persistent state variables are observed. We review some of the basics of discrete choice such as the generalized extreme value distribution, which produces tractable choice probabilities with relatively flexible cross-price elasticities.\n\nReading\nThe main example that we work with throughout the course can be found in Mullins (2022) (pdf).\nRust (1987) is the canonical example demonstrating estimation of dynamic discrete choice models with maximum likelihood and a nested solution method.\nWe show that if one can directly estimate choice probabilities, several tractable approaches produce estimates of structural parameters without repeatedly solving the model. These include Hotz and Miller (1993), Aguirregabiria and Mira (2002), Aguirregabiria and Mira (2007), Pesendorfer and Schmidt-Dengler (2008), and Arcidiacono and Miller (2011). We will review these methods and why they are not appropriate to use in Mullins (2022).\n\n\n\nEstimation of Dynamic Models with Unobserved Heterogeneity\nUsing Mullins (2022) as an example, we talk about the inferential pitfalls that can occur when models fail to account for unobserved heterogeneity. We briefly discuss how this can depend on estimation approaches and sources of identification.\nWe review methods for estimation of dynamic models, including the Expectation-Maximization algorithm (EM) (see, e.g. Arcidiacono and Miller (2011)) and the clustering approach of Bonhomme and Manresa (2015). We review practical considerations for these approaches and introduce the Forward-Back algorithm for implementing EM in hidden Markov Models with time-varying unobserved state variables. We introduce a sparse matrix implementation of this algorithm.\n\n\nIdentification of Dynamic Models with Unobserved Heterogeneity\nWe discuss how either panel data or instrumental variables can facilitate identification of models with unobserved heterogeneity, and briefly review identification results for finite mixtures in panel data settings due to Kasahara and Shimotsu (2009) and Bonhomme, Jochmans, and Robin (2016). Berry and Compiani (2023) analyze identification and estimation of dynamic models with persistent heterogeneity using instrumental variables."
  },
  {
    "objectID": "index.html#assessment",
    "href": "index.html#assessment",
    "title": "Methods for Structural Microeconometrics",
    "section": "Assessment",
    "text": "Assessment\nThere will be 7 problem sets. Your best 5 of these 7 problem sets will be worth 20%. Hence, you can skip two if you want.\nHere is the proposed timeline of due dates. Submissions must be made through Canvas as a notebook (e.g. jupyter or quarto) formatted to html with printed output.\n\n\n\nAssignment\nDue Date\n\n\n\n\nAssignment 1\nMarch 22\n\n\nAssignment 2\nMarch 29\n\n\nAssignment 3\nApril 5\n\n\nAssignment 4\nApril 12\n\n\nAssignment 5\nApril 19\n\n\nAssignment 6\nApril 26\n\n\nAssignment 7\nMay 3"
  },
  {
    "objectID": "index.html#office-hours",
    "href": "index.html#office-hours",
    "title": "Methods for Structural Microeconometrics",
    "section": "Office Hours",
    "text": "Office Hours\nI will provide a link on Canvas to sign up for my weekly office hours."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "assignments/Assignment-1.html",
    "href": "assignments/Assignment-1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "Here is code to load the dataset and do a little cleaning / filtering.\nThe sample is all mothers in the PSID who are unmarried at the time of their first childbirth.\n\nusing CSV, DataFrames, DataFramesMeta\n\ndata = @chain begin\n    CSV.read(\"../children-cash-transfers/data/MainPanelFile.csv\",DataFrame,missingstring = \"NA\")\n    @select :MID :year :wage :hrs :earn :SOI :CPIU :WelfH :FSInd\n    @subset :year.&gt;=1985 :year.&lt;=2010\n    @transform :AFDC = :WelfH.&gt;0\n    @rename :FS = :FSInd\n    end\n\n89747×10 DataFrame89722 rows omitted\n\n\n\nRow\nMID\nyear\nwage\nhrs\nearn\nSOI\nCPIU\nWelfH\nFS\nAFDC\n\n\n\nInt64\nInt64\nFloat64?\nInt64?\nFloat64?\nInt64\nFloat64\nFloat64?\nInt64?\nBool?\n\n\n\n\n1\n4031\n1990\nmissing\nmissing\nmissing\n43\n0.758793\n0.0\n0\nfalse\n\n\n2\n4031\n1991\nmissing\nmissing\nmissing\n43\n0.790786\n0.0\n0\nfalse\n\n\n3\n4031\n1992\nmissing\nmissing\nmissing\n43\n0.814835\n0.0\n1\nfalse\n\n\n4\n4031\n1993\nmissing\nmissing\nmissing\n43\n0.839034\n0.0\n0\nfalse\n\n\n5\n4031\n1994\nmissing\n0\n0.0\n43\n0.860812\n1704.0\n1\ntrue\n\n\n6\n4031\n1995\nmissing\n0\n0.0\n43\n0.88496\n1704.0\n1\ntrue\n\n\n7\n4031\n1996\nmissing\n0\n0.0\n43\n0.910948\n1704.0\n1\ntrue\n\n\n8\n4031\n1997\nmissing\nmissing\nmissing\n43\n0.932244\nmissing\nmissing\nmissing\n\n\n9\n4031\n1998\nmissing\n0\n0.0\n43\n0.946664\n0.0\n1\nfalse\n\n\n10\n4031\n1999\nmissing\nmissing\nmissing\n43\n0.967426\nmissing\nmissing\nmissing\n\n\n11\n4031\n2000\n3.33333\n120\n400.0\n43\n1.0\n0.0\n0\nfalse\n\n\n12\n4031\n2001\nmissing\nmissing\nmissing\n43\n1.02817\nmissing\nmissing\nmissing\n\n\n13\n4031\n2002\nmissing\n0\n0.0\n43\n1.04457\n0.0\n0\nfalse\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n89736\n9308002\n1999\nmissing\nmissing\nmissing\n39\n0.967426\nmissing\nmissing\nmissing\n\n\n89737\n9308002\n2000\nmissing\nmissing\nmissing\n39\n1.0\nmissing\nmissing\nmissing\n\n\n89738\n9308002\n2001\nmissing\nmissing\nmissing\n39\n1.02817\nmissing\nmissing\nmissing\n\n\n89739\n9308002\n2002\nmissing\nmissing\nmissing\n39\n1.04457\nmissing\nmissing\nmissing\n\n\n89740\n9308002\n2003\nmissing\nmissing\nmissing\n39\n1.06857\nmissing\nmissing\nmissing\n\n\n89741\n9308002\n2004\nmissing\nmissing\nmissing\n39\n1.09708\nmissing\nmissing\nmissing\n\n\n89742\n9308002\n2005\nmissing\nmissing\nmissing\n39\n1.13401\nmissing\nmissing\nmissing\n\n\n89743\n9308002\n2006\nmissing\nmissing\nmissing\n39\n1.17054\nmissing\nmissing\nmissing\n\n\n89744\n9308002\n2007\nmissing\nmissing\nmissing\n39\n1.20414\nmissing\nmissing\nmissing\n\n\n89745\n9308002\n2008\nmissing\nmissing\nmissing\n39\n1.25008\nmissing\nmissing\nmissing\n\n\n89746\n9308002\n2009\nmissing\nmissing\nmissing\n39\n1.24608\nmissing\nmissing\nmissing\n\n\n89747\n9308002\n2010\nmissing\nmissing\nmissing\n39\n1.26647\nmissing\nmissing\nmissing\n\n\n\n\n\n\nYou may be unfamiliar with some of these commands, which make use of DataFrames and DataFramesMeta. In particular, think of the @chain macro as a way to compose functions. So for example:\n\nd1 = @chain d2 begin\n    func1(x)\n    func2(y)\n    func3(z)\nend\n\nis equivalent to calling:\n\nd1 = func3(func2(func1(d2,x),y),z)\n\nIf you want to understand better, google is your friend!"
  },
  {
    "objectID": "assignments/Assignment-1.html#setup-loading-the-data",
    "href": "assignments/Assignment-1.html#setup-loading-the-data",
    "title": "Assignment 1",
    "section": "",
    "text": "Here is code to load the dataset and do a little cleaning / filtering.\nThe sample is all mothers in the PSID who are unmarried at the time of their first childbirth.\n\nusing CSV, DataFrames, DataFramesMeta\n\ndata = @chain begin\n    CSV.read(\"../children-cash-transfers/data/MainPanelFile.csv\",DataFrame,missingstring = \"NA\")\n    @select :MID :year :wage :hrs :earn :SOI :CPIU :WelfH :FSInd\n    @subset :year.&gt;=1985 :year.&lt;=2010\n    @transform :AFDC = :WelfH.&gt;0\n    @rename :FS = :FSInd\n    end\n\n89747×10 DataFrame89722 rows omitted\n\n\n\nRow\nMID\nyear\nwage\nhrs\nearn\nSOI\nCPIU\nWelfH\nFS\nAFDC\n\n\n\nInt64\nInt64\nFloat64?\nInt64?\nFloat64?\nInt64\nFloat64\nFloat64?\nInt64?\nBool?\n\n\n\n\n1\n4031\n1990\nmissing\nmissing\nmissing\n43\n0.758793\n0.0\n0\nfalse\n\n\n2\n4031\n1991\nmissing\nmissing\nmissing\n43\n0.790786\n0.0\n0\nfalse\n\n\n3\n4031\n1992\nmissing\nmissing\nmissing\n43\n0.814835\n0.0\n1\nfalse\n\n\n4\n4031\n1993\nmissing\nmissing\nmissing\n43\n0.839034\n0.0\n0\nfalse\n\n\n5\n4031\n1994\nmissing\n0\n0.0\n43\n0.860812\n1704.0\n1\ntrue\n\n\n6\n4031\n1995\nmissing\n0\n0.0\n43\n0.88496\n1704.0\n1\ntrue\n\n\n7\n4031\n1996\nmissing\n0\n0.0\n43\n0.910948\n1704.0\n1\ntrue\n\n\n8\n4031\n1997\nmissing\nmissing\nmissing\n43\n0.932244\nmissing\nmissing\nmissing\n\n\n9\n4031\n1998\nmissing\n0\n0.0\n43\n0.946664\n0.0\n1\nfalse\n\n\n10\n4031\n1999\nmissing\nmissing\nmissing\n43\n0.967426\nmissing\nmissing\nmissing\n\n\n11\n4031\n2000\n3.33333\n120\n400.0\n43\n1.0\n0.0\n0\nfalse\n\n\n12\n4031\n2001\nmissing\nmissing\nmissing\n43\n1.02817\nmissing\nmissing\nmissing\n\n\n13\n4031\n2002\nmissing\n0\n0.0\n43\n1.04457\n0.0\n0\nfalse\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n89736\n9308002\n1999\nmissing\nmissing\nmissing\n39\n0.967426\nmissing\nmissing\nmissing\n\n\n89737\n9308002\n2000\nmissing\nmissing\nmissing\n39\n1.0\nmissing\nmissing\nmissing\n\n\n89738\n9308002\n2001\nmissing\nmissing\nmissing\n39\n1.02817\nmissing\nmissing\nmissing\n\n\n89739\n9308002\n2002\nmissing\nmissing\nmissing\n39\n1.04457\nmissing\nmissing\nmissing\n\n\n89740\n9308002\n2003\nmissing\nmissing\nmissing\n39\n1.06857\nmissing\nmissing\nmissing\n\n\n89741\n9308002\n2004\nmissing\nmissing\nmissing\n39\n1.09708\nmissing\nmissing\nmissing\n\n\n89742\n9308002\n2005\nmissing\nmissing\nmissing\n39\n1.13401\nmissing\nmissing\nmissing\n\n\n89743\n9308002\n2006\nmissing\nmissing\nmissing\n39\n1.17054\nmissing\nmissing\nmissing\n\n\n89744\n9308002\n2007\nmissing\nmissing\nmissing\n39\n1.20414\nmissing\nmissing\nmissing\n\n\n89745\n9308002\n2008\nmissing\nmissing\nmissing\n39\n1.25008\nmissing\nmissing\nmissing\n\n\n89746\n9308002\n2009\nmissing\nmissing\nmissing\n39\n1.24608\nmissing\nmissing\nmissing\n\n\n89747\n9308002\n2010\nmissing\nmissing\nmissing\n39\n1.26647\nmissing\nmissing\nmissing\n\n\n\n\n\n\nYou may be unfamiliar with some of these commands, which make use of DataFrames and DataFramesMeta. In particular, think of the @chain macro as a way to compose functions. So for example:\n\nd1 = @chain d2 begin\n    func1(x)\n    func2(y)\n    func3(z)\nend\n\nis equivalent to calling:\n\nd1 = func3(func2(func1(d2,x),y),z)\n\nIf you want to understand better, google is your friend!"
  },
  {
    "objectID": "assignments/Assignment-1.html#question-1",
    "href": "assignments/Assignment-1.html#question-1",
    "title": "Assignment 1",
    "section": "Question 1",
    "text": "Question 1\nCalculate average welfare participation (AFDC) by year and plot it. What do you think happened with welfare participation in 1996 and after? If you don’t know the historical context, a quick search online or a read of this paper should help you out.\nIf you are new to julia, here is average hours calculated and plotted to get you started.\n\nusing StatsPlots, Statistics\n\nd = @chain data begin\n    groupby(:year)\n    @combine :Hours = mean(skipmissing(:hrs))\n    @subset .!isnan.(:Hours)\nend\n\n@df d plot(:year,:Hours, legend = :none, linewidth = 2)\nxlabel!(\"Year\")\nylabel!(\"Average Welfare Participation\")"
  },
  {
    "objectID": "assignments/Assignment-1.html#question-2",
    "href": "assignments/Assignment-1.html#question-2",
    "title": "Assignment 1",
    "section": "Question 2",
    "text": "Question 2\nNow write code to\n\nDeflate earnings by CPI (CPIU).\nCalculate annual average earnings for each individual (identified by MID).\nDrop individuals with fewer than 10 years of data.\nCategorize individuals by whether their average earnings is below or above the median across individuals.\nPlot average participation in each year for individuals in each of these two categories.\n\nDo you think this pattern is likely to be generated by a model without persistent unobserved heterogeneity? No strictly correct answer here, just curious to read what you think.\nIn case it helps, here is code for the first three steps. You could edit this to add additional operations to the chain or work with d directly.\n\nd = @chain data begin\n    @transform :earn = :earn ./ :CPIU\n    groupby(:MID)\n    @combine :T = sum(.!ismissing.(:earn)) :earn = mean(skipmissing(:earn)) \n    @subset :T .&gt;= 10\nend\n\n1089×3 DataFrame1064 rows omitted\n\n\n\nRow\nMID\nT\nearn\n\n\n\nInt64\nInt64\nFloat64\n\n\n\n\n1\n4031\n10\n40.0\n\n\n2\n4179\n16\n6089.12\n\n\n3\n7030\n11\n4500.53\n\n\n4\n41007\n12\n16147.7\n\n\n5\n41008\n11\n0.0\n\n\n6\n45030\n11\n14374.3\n\n\n7\n45031\n11\n17693.5\n\n\n8\n47031\n11\n15946.7\n\n\n9\n84005\n18\n30769.6\n\n\n10\n105030\n14\n4633.61\n\n\n11\n106173\n13\n17714.4\n\n\n12\n122173\n13\n56275.2\n\n\n13\n126003\n19\n6705.08\n\n\n⋮\n⋮\n⋮\n⋮\n\n\n1078\n6843006\n19\n1805.93\n\n\n1079\n6843173\n19\n5005.44\n\n\n1080\n6845005\n19\n19795.4\n\n\n1081\n6849005\n19\n2450.55\n\n\n1082\n6849188\n15\n23259.0\n\n\n1083\n6853003\n19\n4856.42\n\n\n1084\n6862005\n11\n18899.4\n\n\n1085\n6862008\n19\n26634.8\n\n\n1086\n6864002\n19\n8695.92\n\n\n1087\n6864003\n18\n13627.5\n\n\n1088\n6867013\n13\n389.097\n\n\n1089\n6872171\n17\n3294.07"
  },
  {
    "objectID": "assignments/Assignment-1.html#question-3",
    "href": "assignments/Assignment-1.html#question-3",
    "title": "Assignment 1",
    "section": "Question 3",
    "text": "Question 3\nThis question is to familiarize you with the module Tranfers.jl which will enable you to calculate post-tax and transfer income for individuals given their earnings, non-labor income, state, year, and family size. The function budget in this module takes the arguments:\n\nE: monthly earnings (either real or nominal)\nN: monthly non-labor income (real or nominal)\nSOI: the SOI code for state of residence\nyear: calendar year\nnum_kids: the number of children\ncpi: set to 1. if E and N are nominal\np: equal to 0 if no programs, 1 if food stamps, 2 if food stamps + welfare.\n\nFor example the function call:\n\nTransfers.budget(500.,0.,23,2000,2,1.,2)\n\ncalculates net income for a mother in Michigan (SOI code 23) with 2 kids, nominal labor income of $500 a month in the year 2000, and no non-labor income.\n\ninclude(\"../children-cash-transfers/src/Transfers.jl\")\n\nTransfers.budget(500.,0.,23,2000,2,1.,2)\n\n978.5408333333334\n\n\nCreate a graph that represents total net transfers for a single mother with two kids in the years 1990 and 2000 and in the states of Mississippi and New York. Depict these transfers as a function of earnings between the values of 0 and $1,000 a month (nominal). You can assume that all households are receiving both food stamps and welfare.\nWhat do you make of the differences in these transfers across states and over time?"
  },
  {
    "objectID": "assignments/Assignment-2.html",
    "href": "assignments/Assignment-2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "We are building toward estimating a dynamic discrete choice model with persistent unobserved heterogeneity. To make a start, in this problem set you will estimate a static discrete choice problem on the data."
  },
  {
    "objectID": "assignments/Assignment-2.html#setup-code-for-mle",
    "href": "assignments/Assignment-2.html#setup-code-for-mle",
    "title": "Assignment 2",
    "section": "Setup: Code for MLE",
    "text": "Setup: Code for MLE\n\nReading in Data\nYou are going to build on the code below that estimates a very simple model of labor supply and program participation.\nFirst, here is a chunk of code to read in the data and prepare it. The variables in julia DataFrames are typically not type stable which can slow down your code considerably. So you will note that in the final step here I bring the variables I want to use out of a DataFrame and into a named tuple with vectors containing a fixed type.\n\nusing CSV, DataFrames, DataFramesMeta, Optim\ninclude(\"../children-cash-transfers/src/Transfers.jl\")\n\n# for this simple model we can just drop missing data. When we estimate the model with persistent latent heterogeneity, we will need complete panels (including years where choices are missing).\n\ndata = @chain begin\n    CSV.read(\"../children-cash-transfers/data/MainPanelFile.csv\",DataFrame,missingstring = \"NA\")\n    #@select :MID :year :wage :hrs :earn :SOI :CPIU :WelfH :FSInd :num_child :age\n    @subset :year.&gt;=1985 :year.&lt;=2010\n    @transform :AFDC = :WelfH.&gt;0 \n    @rename :FS = :FSInd\n    @transform :P  = :FS + :AFDC :H = min.(2,round.(Union{Int64, Missing},:hrs / (52*20)))\n    @subset .!ismissing.(:P) .&& .!ismissing.(:H)\n    @transform @byrow :wage = begin\n        if :hrs&gt;0 && :earn&gt;0\n            return :earn / :hrs / :CPIU\n        else\n            return missing\n        end\n    end\nend\n\ndata_mle = (;P = Int64.(data.P), H = Int64.(data.H), year = data.year, age = data.age,\n            soi = data.SOI, num_kids = data.num_child, cpi = data.CPIU,\n            logwage = log.(coalesce.(data.wage,1.)),wage_missing = ismissing.(data.wage))\n\n(P = [2, 2, 2, 1, 0, 0, 0, 2, 1, 0  …  2, 2, 1, 2, 0, 0, 1, 1, 1, 1], H = [0, 0, 0, 0, 0, 0, 0, 0, 0, 2  …  0, 0, 2, 2, 2, 2, 0, 0, 0, 0], year = [1994, 1995, 1996, 1998, 2000, 2002, 2004, 2006, 2008, 1990  …  1991, 1992, 1991, 1992, 1991, 1992, 1991, 1992, 1991, 1992], age = [21, 22, 23, 25, 27, 29, 31, 33, 35, 17  …  21, 22, 23, 24, 39, 40, 30, 31, 25, 26], soi = [43, 43, 43, 43, 43, 43, 43, 43, 43, 17  …  44, 44, 7, 7, 5, 5, 39, 39, 39, 39], num_kids = [2, 2, 3, 3, 3, 3, 3, 3, 3, 1  …  2, 2, 2, 2, 3, 3, 4, 4, 2, 2], cpi = [0.860812349005761, 0.884959812302546, 0.910948243820851, 0.946664188812488, 1.0, 1.04457233785542, 1.09707768072849, 1.17054218546739, 1.25008130459022, 0.758792510685746  …  0.790785866939231, 0.8148346032336, 0.790785866939231, 0.8148346032336, 0.790785866939231, 0.8148346032336, 0.790785866939231, 0.8148346032336, 0.790785866939231, 0.8148346032336], logwage = [0.0, 0.0, 0.0, 0.0, 1.2039728043259361, 0.0, 0.0, 0.0, 0.0, 0.8230555833449215  …  0.0, 0.0, 2.6512574120409043, 2.3314412292534223, 1.265948758245773, 1.8744481199656744, 0.0, 0.0, 0.0, 0.0], wage_missing = Bool[1, 1, 1, 1, 0, 1, 1, 1, 1, 0  …  1, 1, 0, 0, 0, 0, 1, 1, 1, 1])\n\n\n\n\nThe Model\nConsider a static model with 9 discrete choices. Hours choices are given by \\(H_{j}\\in\\{0,20,40\\}\\) and participation choices indicated by \\(P_{j}\\in\\{0,1,2\\}\\). Individuals may choose any combination of these, with a Type I extreme value distributed shock \\(\\epsilon_{j}\\) for choice \\(j\\) that is iid over time and across individuals. The scale of these shocks is given by \\(\\sigma\\).\nUtility for individual \\(i\\) at time \\(t\\) is given by:\n\\[ U_{itj} = \\log(\\max\\{50,Y_{it}(W_{it}H_{j})\\}) + \\alpha_{l}\\log(112 - H_{j}) - \\alpha_{P,1}\\mathbf{1}\\{P_{j}&gt;0\\} - \\alpha_{P,2}\\mathbf{1}\\{P_{j}&gt;1\\} \\]\nwhere \\(Y_{it}\\) is a net income function for individual \\(i\\) at time \\(t\\) and depends on their earnings (\\(W_{it}H_{j}\\)), the number of children in the household, and the policy environment in the individual’s state of residence.\nWages are a deterministic function of age only:\n\\[ \\log(W_{it}) = \\gamma_{0} + \\gamma_{1}\\text{Age}_{it} + \\gamma_{2}\\text{Age}_{it}^2 \\]\nand are measured with normally distributed iid measurement error:\n\\[ \\log(W^{o}_{it}) = \\log(W_{it}) + \\zeta_{it},\\qquad\\zeta_{it}\\sim\\mathcal{N}(0,\\sigma^2_{W}) \\]\nThe code below calculates utility and indexes choices.\n\nj_idx(p,h) = p*3 + h + 1\nfunction utility(p,h,soi,cpi,year,num_kids,wage,pars)\n    (;αl,Hgrid,σ,αP) = pars\n    hrs = Hgrid[1+h]\n    earn = wage * hrs\n    net_income = max(50.,Transfers.budget(earn,0.,soi,year,num_kids,cpi,p))\n    return log(net_income) + αl*log(112-hrs) - αP[1]*(p&gt;0) - αP[2]*(p&gt;1)\nend\n\npars = (;αl = 1., σ = 1., σW = 1., γ = zeros(3),\n    Hgrid = [0,20.,40.],αP = zeros(2))\n\n(αl = 1.0, σ = 1.0, σW = 1.0, γ = [0.0, 0.0, 0.0], Hgrid = [0.0, 20.0, 40.0], αP = [0.0, 0.0])\n\n\nChoice probabilities are given by the logit formula.\n\nfunction choice_prob!(logP,it,data,pars)\n    (;σ,γ) = pars\n    wage = exp(γ[1] + γ[2] * data.age[it] + γ[3] * data.age[it]^2)\n    denom = 0.\n    umax = -Inf\n    for p in 0:2\n        for h in 0:2\n            j = j_idx(p,h)\n            u = utility(p,h,data.soi[it],data.cpi[it],data.year[it],data.num_kids[it],wage,pars)\n            logP[j] = u / σ\n            umax = u&gt;umax ? u : umax\n        end\n    end\n    logP[:] .-= umax / σ\n    denom = log(sum(exp.(logP)))\n    logP[:] .-= denom #&lt;- nornalize choice probabilities\nend\n\nchoice_prob! (generic function with 1 method)\n\n\nAnd so the log-likelihood takes a simple form.\n\nfunction log_likelihood(logP,it,data,pars)\n    (;γ,σW) = pars\n    ll = 0.\n    if !data.wage_missing[it]\n        ll += -((data.logwage[it] - γ[1] - γ[2]*data.age[it] - γ[3]*data.age[it]^2) / σW)^2 - log(σW)\n    end\n    choice_prob!(logP,it,data,pars)\n    j = j_idx(data.P[it],data.H[it])\n    ll += logP[j]\n    return ll\nend\n\nfunction update(x,p)\n    αl = exp(x[1])\n    σ = exp(x[2])\n    γ = x[3:5]\n    σW = exp(x[6])\n    αP = x[7:8]\n    return (;p...,αl,σ,σW,αP,γ)\nend\n\nfunction log_likelihood(x,data,pars)\n    pars = update(x,pars)\n    logP = zeros(eltype(x),9)\n    ll = 0.\n    for it in eachindex(data.P)\n        ll += log_likelihood(logP,it,data,pars)\n    end\n    return ll\nend\n\nlog_likelihood (generic function with 2 methods)\n\n\nWe can use Optim to maximize the log-likelihood:\n\nx0 = zeros(8)\nx0 = [0.,0.,log(10.),0.,0.,0.,0.,0.]\nres = optimize(x-&gt;-log_likelihood(x,data_mle,pars),x0,BFGS(),autodiff=:forward,Optim.Options(show_trace = true))\npars = update(res.minimizer,pars)\n\nIter     Function value   Gradient norm \n     0     7.729550e+04     1.005681e+06\n * time: 0.0067348480224609375\n     1     7.728174e+04     1.362621e+05\n * time: 0.46323084831237793\n     2     7.678584e+04     2.375208e+05\n * time: 0.5899059772491455\n     3     7.041391e+04     1.155246e+07\n * time: 0.848891019821167\n     4     7.033009e+04     1.359653e+07\n * time: 1.0774779319763184\n     5     6.446005e+04     1.276115e+07\n * time: 1.3872449398040771\n     6     6.440142e+04     1.297836e+07\n * time: 1.5771429538726807\n     7     6.388572e+04     1.316915e+07\n * time: 1.633699893951416\n     8     6.363983e+04     1.197498e+07\n * time: 1.6910300254821777\n     9     6.306659e+04     1.217467e+07\n * time: 1.7291948795318604\n    10     5.970071e+04     6.242068e+06\n * time: 1.7861368656158447\n    11     5.913225e+04     1.838362e+06\n * time: 1.8247549533843994\n    12     5.898860e+04     3.725160e+05\n * time: 1.862968921661377\n    13     5.897031e+04     1.146177e+03\n * time: 1.920003890991211\n    14     5.893098e+04     3.213296e+05\n * time: 1.9772908687591553\n    15     5.889641e+04     4.670839e+05\n * time: 2.0341718196868896\n    16     5.886231e+04     6.564625e+05\n * time: 2.0910239219665527\n    17     5.883989e+04     2.067935e+05\n * time: 2.148289918899536\n    18     5.883335e+04     1.143504e+05\n * time: 2.186215877532959\n    19     5.883128e+04     1.938827e+05\n * time: 2.2432708740234375\n    20     5.872181e+04     2.425773e+06\n * time: 2.5086259841918945\n    21     5.871558e+04     2.659735e+06\n * time: 2.6778719425201416\n    22     5.869667e+04     2.948221e+06\n * time: 2.715939998626709\n    23     5.866938e+04     3.241386e+06\n * time: 2.792001962661743\n    24     5.860059e+04     3.320767e+06\n * time: 2.829859972000122\n    25     5.853216e+04     3.310494e+06\n * time: 2.8678648471832275\n    26     5.829643e+04     2.687666e+06\n * time: 2.9062747955322266\n    27     5.802855e+04     7.037545e+05\n * time: 2.9442379474639893\n    28     5.799332e+04     3.111438e+05\n * time: 2.9819729328155518\n    29     5.798341e+04     9.587529e+04\n * time: 3.019860029220581\n    30     5.797958e+04     2.198829e+05\n * time: 3.0580317974090576\n    31     5.797779e+04     2.395297e+05\n * time: 3.096052885055542\n    32     5.797510e+04     1.735846e+05\n * time: 3.1561620235443115\n    33     5.797480e+04     2.058438e+04\n * time: 3.195523977279663\n    34     5.797478e+04     1.438637e+03\n * time: 3.2377889156341553\n    35     5.797478e+04     4.051164e+02\n * time: 3.278334856033325\n    36     5.797478e+04     2.580092e+01\n * time: 3.3357489109039307\n    37     5.797478e+04     5.659174e+00\n * time: 3.393019914627075\n    38     5.797478e+04     2.421590e-01\n * time: 3.4309909343719482\n    39     5.797478e+04     2.800754e-02\n * time: 3.4690258502960205\n    40     5.797478e+04     1.614311e-03\n * time: 3.5067529678344727\n    41     5.797478e+04     6.378983e-06\n * time: 3.544942855834961\n    42     5.797478e+04     4.206356e-09\n * time: 3.601470947265625\n\n\n(αl = 2.854623378392939, σ = 0.9509286759263789, σW = 1.0217495087252684, γ = [-0.02362075058294272, 0.10877398375255734, -0.0012722347394313303], Hgrid = [0.0, 20.0, 40.0], αP = [2.0353016361355447, 1.0137619542631433])"
  },
  {
    "objectID": "assignments/Assignment-2.html#question-1",
    "href": "assignments/Assignment-2.html#question-1",
    "title": "Assignment 2",
    "section": "Question 1",
    "text": "Question 1\nWrite code to calculate the standard errors for these parameters and present the estimates with standard errors in a table."
  },
  {
    "objectID": "assignments/Assignment-2.html#question-2",
    "href": "assignments/Assignment-2.html#question-2",
    "title": "Assignment 2",
    "section": "Question 2",
    "text": "Question 2\nWhat sources of variation are identifying \\(\\sigma\\), the responsiveness of choices to changes in the payoffs? How is the responsivess of program participation and labor supply to changes in incentives limited in this framework?"
  },
  {
    "objectID": "assignments/Assignment-2.html#question-3",
    "href": "assignments/Assignment-2.html#question-3",
    "title": "Assignment 2",
    "section": "Question 3",
    "text": "Question 3\nRe-estimate the model with a one layer nested logit structure, where the individual first makes one of the three participation choices before making one of the three hours choices. That is, if the choices can be ordered as: \\[ \\{P_{j}\\}_{j=1}^9 = \\{0,0,0,1,1,1,2,2,2\\}, \\{H_{j}\\}_{j=1}^9 = \\{0,20,40,0,20,40,0,20,40\\} \\]\nthen the partition is:\n\\[ \\mathcal{B} = \\{\\{1,2,3\\},\\{4,5,6\\},\\{7,8,9\\}\\} \\]\nLet \\(\\sigma_{H}\\) be the dispersion of shocks within each partition and \\(\\sigma_{P}\\) be the dispersion of shocks across partitions. Intuitively, how are these dispersion parameters identified? (Hint: think about what is changing payoffs across observations and think about the two dimensions of the discrete choice)."
  },
  {
    "objectID": "assignments/Assignment-2.html#question-4",
    "href": "assignments/Assignment-2.html#question-4",
    "title": "Assignment 2",
    "section": "Question 4",
    "text": "Question 4\nWhat sort of variation do you think is in the data that we are failing to put in our model? What do you think are the implications for key parameter estimates?"
  }
]